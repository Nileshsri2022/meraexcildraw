"""
AI Canvas Chat Assistant â€” Python Microservice

A streaming chatbot powered by MiniMax M2.1 via NVIDIA AI Endpoints.
Understands the whiteboard canvas context and helps users create,
modify, and analyze their diagrams and drawings.

Endpoints:
    POST /chat          â€” Streaming SSE chat
    POST /chat/context  â€” Update canvas context (elements on board)
    GET  /health        â€” Health check
"""

import os
import re
import json
import uuid
import asyncio
from typing import AsyncGenerator
from datetime import datetime

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

from langchain_nvidia_ai_endpoints import ChatNVIDIA
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
import markdown as md

load_dotenv()

# â”€â”€â”€ Markdown â†’ HTML converter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MD_EXTENSIONS = ["fenced_code", "tables", "nl2br", "sane_lists", "smarty"]

# Regex to match <think>...</think> blocks (including multiline)
THINK_PATTERN = re.compile(r"<think>.*?</think>", re.DOTALL)

def strip_think_tags(text: str) -> str:
    """Remove <think>...</think> reasoning blocks from model output."""
    cleaned = THINK_PATTERN.sub("", text)
    return cleaned.lstrip("\n")

def md_to_html(text: str) -> str:
    """Convert LLM markdown response to clean HTML for the frontend."""
    return md.markdown(text, extensions=MD_EXTENSIONS)

# â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

NVIDIA_API_KEY = os.getenv("NVIDIA_API_KEY", "")
CHAT_MODEL = os.getenv("CHAT_MODEL", "minimaxai/minimax-m2.1")
CHAT_PORT = int(os.getenv("CHAT_PORT", "3003"))

if not NVIDIA_API_KEY:
    raise ValueError("NVIDIA_API_KEY is required. Set it in .env")

# â”€â”€â”€ LangChain Client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

llm = ChatNVIDIA(
    model=CHAT_MODEL,
    api_key=NVIDIA_API_KEY,
    temperature=0.8,
    top_p=0.95,
    max_completion_tokens=4096,
)

# â”€â”€â”€ Canvas-Aware System Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT = """You are **Canvas AI**, an intelligent assistant embedded in a collaborative whiteboard application (Excalidraw-based).

## Your Capabilities
- Help users brainstorm, plan, and organize ideas on their whiteboard
- Suggest diagram structures (flowcharts, mind maps, class diagrams, sequence diagrams)
- **DRAW DIRECTLY on the canvas** by emitting canvas actions
- Analyze the current canvas content and provide insights
- Help with writing, editing, and refining text on the board
- Explain concepts, provide code snippets, and answer questions
- Suggest visual improvements and layout optimizations

## ðŸŽ¯ Drawing on Canvas â€” CANVAS ACTIONS
When the user asks you to draw, create, add, or place something on the canvas, you MUST emit a ```canvas_action code block containing a JSON array of elements. The frontend will parse this and create actual shapes on the whiteboard.

### Supported element types and their properties:
```
{{
  "type": "rectangle" | "ellipse" | "diamond" | "text" | "arrow" | "line",
  "x": number,           // X position (default: auto-arranged)
  "y": number,           // Y position (default: auto-arranged)
  "width": number,       // Width in pixels (default: 200)
  "height": number,      // Height in pixels (default: 100)
  "text": string,        // Text inside the shape (for rectangle, ellipse, diamond) or the text content (for text type)
  "backgroundColor": string,  // Fill color (e.g., "#3b82f6", "#22c55e", "#ef4444", "#f59e0b", "#8b5cf6", "#ec4899")
  "strokeColor": string,      // Border color (default: "#1e1e1e")
  "fontSize": number,         // Font size for text elements (default: 20)
  "startId": string,          // For arrows: ID of the source element to connect from
  "endId": string             // For arrows: ID of the target element to connect to
}}
```

### IMPORTANT RULES for canvas actions:
1. Give each element a unique "id" field (e.g., "el-1", "el-2") so arrows can reference them.
2. Space elements apart â€” at least 250px between centers horizontally, 200px vertically.
3. Use pleasant colors: blues (#3b82f6), greens (#22c55e), reds (#ef4444), yellows (#f59e0b), purples (#8b5cf6), pinks (#ec4899).
4. For flowcharts and diagrams, create shapes first, then connect them with arrows using startId/endId.
5. Always include a short text explanation BEFORE the canvas_action block.

### Example â€” User says "Draw a login flowchart":

Here's a login flow for your app! ðŸŽ¨

```canvas_action
[
  {{"id": "el-1", "type": "rectangle", "x": 100, "y": 100, "width": 200, "height": 80, "text": "Login Page", "backgroundColor": "#3b82f6"}},
  {{"id": "el-2", "type": "diamond", "x": 100, "y": 300, "width": 220, "height": 120, "text": "Valid?", "backgroundColor": "#f59e0b"}},
  {{"id": "el-3", "type": "rectangle", "x": -150, "y": 520, "width": 200, "height": 80, "text": "Show Error", "backgroundColor": "#ef4444"}},
  {{"id": "el-4", "type": "rectangle", "x": 350, "y": 520, "width": 200, "height": 80, "text": "Dashboard", "backgroundColor": "#22c55e"}},
  {{"id": "a-1", "type": "arrow", "startId": "el-1", "endId": "el-2"}},
  {{"id": "a-2", "type": "arrow", "startId": "el-2", "endId": "el-3", "text": "No"}},
  {{"id": "a-3", "type": "arrow", "startId": "el-2", "endId": "el-4", "text": "Yes"}}
]
```

## Response Guidelines
1. **Be concise** â€” Users are working visually. Keep responses focused and actionable.
2. **Use formatting** â€” Use markdown with headers, lists, and code blocks.
3. **Canvas actions** â€” When the user asks to draw/create/add anything, USE canvas_action blocks. This is your superpower!
4. **Canvas awareness** â€” When canvas context is provided, reference specific elements the user has drawn.
5. **Proactive suggestions** â€” If you notice improvements, suggest them naturally.
6. **Friendly tone** â€” Be a collaborative partner, not a formal assistant.

## Current Canvas Context
{canvas_context}
"""

# â”€â”€â”€ In-Memory Session Storage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class Session:
    """Chat session with conversation history and canvas context."""

    def __init__(self):
        self.messages: list = []
        self.canvas_context: str = "No canvas elements loaded yet."
        self.created_at: str = datetime.now().isoformat()

    def get_system_message(self) -> SystemMessage:
        return SystemMessage(
            content=SYSTEM_PROMPT.format(canvas_context=self.canvas_context)
        )

    def get_langchain_messages(self) -> list:
        """Build the full message list for the LLM."""
        result = [self.get_system_message()]
        # Keep last 20 messages to avoid context overflow
        recent = self.messages[-20:]
        result.extend(recent)
        return result


# Session store: session_id -> Session
sessions: dict[str, Session] = {}


def get_or_create_session(session_id: str | None) -> tuple[str, Session]:
    """Get existing session or create a new one."""
    if session_id and session_id in sessions:
        return session_id, sessions[session_id]
    new_id = session_id or str(uuid.uuid4())
    sessions[new_id] = Session()
    return new_id, sessions[new_id]


# â”€â”€â”€ Pydantic Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=4000)
    session_id: str | None = None

class CanvasContextRequest(BaseModel):
    session_id: str
    elements: list[dict] = Field(default_factory=list)
    description: str | None = None

class ClearRequest(BaseModel):
    session_id: str

# â”€â”€â”€ FastAPI App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

app = FastAPI(
    title="Canvas AI Chat Service",
    description="Streaming chat microservice for the AI Whiteboard",
    version="1.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# â”€â”€â”€ Endpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/health")
async def health():
    return {
        "status": "ok",
        "model": CHAT_MODEL,
        "sessions": len(sessions),
    }


@app.post("/chat")
async def chat(req: ChatRequest):
    """
    Streaming chat endpoint using Server-Sent Events.
    Each chunk is a JSON object: { "token": "...", "done": false }
    Final chunk: { "token": "", "done": true, "session_id": "..." }
    """
    session_id, session = get_or_create_session(req.session_id)

    # Add user message to history
    session.messages.append(HumanMessage(content=req.message))

    # Build messages for LLM
    messages = session.get_langchain_messages()

    async def generate() -> AsyncGenerator[str, None]:
        full_response = ""
        inside_think = False

        try:
            # Stream from LangChain
            for chunk in llm.stream(messages):
                token = chunk.content
                if token:
                    full_response += token

                    # --- Filter out <think>...</think> tokens during stream ---
                    if "<think>" in token:
                        inside_think = True
                    if inside_think:
                        if "</think>" in token:
                            inside_think = False
                            # There might be useful text after </think>
                            after = token.split("</think>", 1)[1]
                            if after.strip():
                                data = json.dumps({"token": after, "done": False})
                                yield f"data: {data}\n\n"
                        continue  # skip this token entirely (it's thinking)

                    data = json.dumps({"token": token, "done": False})
                    yield f"data: {data}\n\n"

            # Strip think tags from full response before saving & converting
            clean_response = strip_think_tags(full_response)

            # Save assistant response to history
            session.messages.append(AIMessage(content=clean_response))

            # Convert clean response from markdown to HTML
            html = md_to_html(clean_response)

            # Send final event with rendered HTML
            done_data = json.dumps({
                "token": "",
                "done": True,
                "html": html,
                "session_id": session_id,
            })
            yield f"data: {done_data}\n\n"

        except Exception as e:
            error_data = json.dumps({
                "token": "",
                "done": True,
                "error": str(e),
                "session_id": session_id,
            })
            yield f"data: {error_data}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Session-Id": session_id,
        },
    )


@app.post("/chat/context")
async def update_canvas_context(req: CanvasContextRequest):
    """Update the canvas context for a session so the AI knows what's on the board."""
    if req.session_id not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    session = sessions[req.session_id]

    if req.description:
        session.canvas_context = req.description
    elif req.elements:
        # Build a concise summary of canvas elements
        summary_parts = []
        type_counts: dict[str, int] = {}

        for el in req.elements[:50]:  # Limit to 50 elements
            el_type = el.get("type", "unknown")
            type_counts[el_type] = type_counts.get(el_type, 0) + 1

            # Extract meaningful text content
            text = el.get("text", "").strip()
            if text and len(text) < 200:
                summary_parts.append(f'- {el_type}: "{text}"')

        counts_str = ", ".join(f"{count} {t}(s)" for t, count in type_counts.items())
        elements_str = "\n".join(summary_parts[:20])  # Max 20 text elements

        session.canvas_context = (
            f"Canvas has {len(req.elements)} elements: {counts_str}.\n"
            f"Text content found:\n{elements_str}" if elements_str
            else f"Canvas has {len(req.elements)} elements: {counts_str}. No text content."
        )
    else:
        session.canvas_context = "Canvas is empty."

    return {"status": "ok", "context_length": len(session.canvas_context)}


@app.post("/chat/clear")
async def clear_session(req: ClearRequest):
    """Clear conversation history for a session."""
    if req.session_id in sessions:
        sessions[req.session_id].messages.clear()
        return {"status": "ok", "message": "Session cleared"}
    return {"status": "ok", "message": "Session not found (already clean)"}


@app.delete("/chat/session/{session_id}")
async def delete_session(session_id: str):
    """Delete an entire session."""
    sessions.pop(session_id, None)
    return {"status": "ok"}


# â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    import uvicorn
    print(f"[Canvas AI] Chat Service starting on port {CHAT_PORT}")
    print(f"   Model: {CHAT_MODEL}")
    uvicorn.run(app, host="0.0.0.0", port=CHAT_PORT)
